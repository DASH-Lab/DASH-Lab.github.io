---
layout: page
title: Publications
permalink: /Publications/
---

<h1 class="page-title">Publications</h1>





<div style="margin-top:2vw;">
    <h4 style="margin-top:20px"><b>2021</b></h4>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">
        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>SmartConDetect: Highly Accurate Smart Contract CodeVulnerability Detection Mechanism using BERT</b></a>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small>  Sowon Jeon, Gilhee Lee, Hyoungshick Kim and <i><b>Simon S. Woo*</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 2021 KDD Workshop on Programming Language Processing (PLP 2021) </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small>In this paper, we propose SmartConDetect to detect security vulnerabilities in smart contracts written in Solidity, which the most popular programming language for writing smart contracts on the Ethereum platform. SmartConDetect is designed as a static analysis tool to extract code fragments from smart contracts in Solidity and analyze code patterns using a pre-trained BERT model and a bidirectional LSTM model.</small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.google.com/search?q=SmartConDetect%3A+Highly+Accurate+Smart+Contract+CodeVulnerability+Detection+Mechanism+using+BERT&oq=SmartConDetect%3A+Highly+Accurate+Smart+Contract+CodeVulnerability+Detection+Mechanism+using+BERT&aqs=chrome..69i57j69i58.269j0j7&sourceid=chrome&ie=UTF-8">paper</a>][<a
                                    href="https://www.google.com/">project</a>]</small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="smartcondetect.png" style="max-height:220px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    
    <div style="display: flex;flex-direction: row;justify-content: space-between;">
        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Exploring the Asynchronous of the Frequency Spectra of GAN-generated Facial Images</b></a>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Le Minh Binh and <i><b>Simon S. Woo*</b> </i></small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b><a href="https://ssdl2021.github.io/">International Workshop on Safety and Security of Deep Learning</a>, IJCAI 2021 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small>In this paper, we propose a new approach that explores the asynchronous frequency spectra of color channels, which is simple but effective for training both unsupervised and supervised learning models to distinguish GAN-based synthetic images.</small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.google.com/search?q=Exploring+the+Asynchronous+of+the+Frequency+Spectra+of+GAN-generated+Facial+Images&oq=Exploring+the+Asynchronous+of+the+Frequency+Spectra+of+GAN-generated+Facial+Images&aqs=chrome..69i57j69i61.257j0j7&sourceid=chrome&ie=UTF-8">paper</a>][<a
                                    href="https://github.com/Leminhbinh0209/Asynchronous-in-Frequency-domain-of-GAN-images">project</a>]</small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="ijcai2021_overall_diag.png" style="max-height:220px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>SAROD: Efficient End-To-End Object Detection on SAR Images with Reinforcement Learning</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> JunHyung Kang, HyeonSeong Jeon, YoungOh Bang, and <i><b>Simon S. Woo*</b> </i></small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 28th IEEE International Conference on Image Processing (ICIP 2021)</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small>In this work, we introduce SAROD, a novel efficient end-to-end object detection 
                            framework on SAR images based on Reinforcement Learning (RL), to balance the trade-offs between high accuracy and efficiency.</small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://github.com/JunHyungKang/SAROD_ICIP">paper</a>][<a
                                    href="https://github.com/JunHyungKang/SAROD_ICIP">project</a>]</small>
                        </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="sarod.jpg" style="max-height:220px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>


    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b> FReTAL: Generalizing Deepfake Detection using Knowledge Distillation and Representation
                                Learning</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Minha Kim, Shahroz
                                Tariq, <i><b>Simon S. Woo*</b> </i></small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> <a
                                        href="https://sites.google.com/view/mediaforensics2021/"> WORKSHOP ON MEDIA
                                        FORENSICS</a>, CVPR 2021 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small>As GAN-based video
                                and image manipulation technologies become more sophisticated and easily accessible,
                                there is an urgent need for effective deepfake detection technologies. Moreover, various
                                deepfake generation techniques have emerged over the past few years.</small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.google.com/search?q=FReTAL%3A+Generalizing+Deepfake+Detection+using+Knowledge+Distillation+and+Representation+Learning&oq=FReTAL%3A+Generalizing+Deepfake+Detection+using+Knowledge+Distillation+and+Representation+Learning&aqs=chrome..69i57j69i58.351j0j7&sourceid=chrome&ie=UTF-8">paper</a>][<a
                                    href="https://www.google.com/search?q=FReTAL%3A+Generalizing+Deepfake+Detection+using+Knowledge+Distillation+and+Representation+Learning&oq=FReTAL%3A+Generalizing+Deepfake+Detection+using+Knowledge+Distillation+and+Representation+Learning&aqs=chrome..69i57j69i58.351j0j7&sourceid=chrome&ie=UTF-8">project</a>]</small>
                        </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="fretalgd.png" style="max-height:220px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>


    <div style="display: flex;flex-direction: row;justify-content: space-between;">
        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b> Neural Network Laundering: Removing Black-Box Backdoor Watermarks from Deep Neural
                                Networks</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> William Aiken,
                                Hyoungshick Kim, <i><b>Simon S. Woo*</b> </i>, and Jungwoo Ryoo </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Elsevier
                                    Computers & Security, accepted on April 2021 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>SCIE Q1 IF=3.58</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small>Creating a
                                state-of-the-art deep-learning system requires vast amounts of data, expertise, and
                                hardware, yet research into embedding copyright protection for neural networks has been
                                limited. One of the main methods for achieving such protection involves relying on the
                                susceptibility of neural networks to backdoor attacks, but the robustness of these
                                tactics has been primarily evaluated against pruning, fine-tuning, and model inversion
                                attacks. </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.sciencedirect.com/science/article/pii/S0167404821001012">paper</a>][<a
                                    href="https://www.sciencedirect.com/science/article/pii/S0167404821001012">project</a>]</small>
                        </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="nb.jpg" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">
        <div style="margin-left: 25px;margin-right:10px;">
            <table>
                <thead>
                    <tr>
                        <a><b> Am I a Real or Fake Celebrity? Measuring Commercial Face Recognition Web APIs under
                                Deepfake Impersonation Attack</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Shahroz Tariq, Sowon
                                Jeon, and <i><b>Simon S. Woo*</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>Arxiv</b>
                            </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small>This work provides a
                                measurement study on the robustness of black-box commercial face recognition APIs
                                against Deepfake Impersonation (DI) attacks using celebrity recognition APIs as an
                                example case study We achieved maximum success rates of 78.0% and 99.9% for targeted
                                (ie, precise match) and non-targeted (ie, match with any celebrity) attacks,
                                respectively. Moreover, we propose practical defense strategies to mitigate DI attacks,
                                reducing the attack success rates to as low as 0% and 0.02% for targeted and
                                non-targeted attacks, respectively.</small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://arxiv.org/abs/2103.00847">paper</a>]
                                [<a
                                    href="https://www.biometricupdate.com/202103/researchers-show-deepfakes-can-beat-face-biometric-web-services-propose-defense-strategy">News-1</a>]
                                [<a
                                    href="https://www.digitalinformationworld.com/2021/03/social-media-users-warned-of-deepfake.html">News-2</a>]
                                [<a
                                    href="https://medium.com/paradigm-fund/bt-biometric-digital-id-providers-partner-with-microsoft-on-decentralized-id-passwordless-pilot-c7c2aab797d1">News-3</a>]
                                [<a
                                    href="https://venturebeat.com/2021/03/05/study-warns-deepfakes-can-fool-facial-recognition/">
                                    News-4</a>]
                                [<a
                                    href="https://epocanegocios.globo.com/Tecnologia/noticia/2021/03/deepfakes-podem-enganar-ate-mesmo-inteligencia-artificial.html">News-5</a>]
                                [<a
                                    href="https://www.etcentric.org/study-suggests-deepfakes-fool-top-facial-recognition-tech/">News-6</a>]
                                [<a
                                    href="https://www.archyworldys.com/deepfakes-can-trick-facial-recognition/">News-7</a>]
                                [<a
                                    href="https://www.thespuzz.com/study-warns-deepfakes-can-fool-facial-recognition/">News-8</a>]
                                [<a
                                    href="https://publicnews.in/tech/study-warns-deepfakes-can-fool-facial-recognition/">News-9</a>]
                                [<a
                                    href="https://famousnews.org/study-warns-deepfakes-can-recognize-the-face/">News-10</a>]
                                [<a
                                    href="https://www.trendyvoice.in/study-warns-deepfakes-can-fool-facial-recognition/?amp">News-11</a>]
                            </small> </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle; text-align:center">
            <img src="airor.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b> Revitalizing Self-Organizing Map: Anomaly Detection using Forecasting Error
                                Patterns</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Young Geun Kim,
                                    Jeong-Han Yun, Siho Han, Hyoung Chun Kimand <b>Simon S. Woo*</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>36th
                                    International Conference on ICT Systems Security and Privacy Protection – IFIP SEC
                                    2021, 22–24 June 2021 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>BK Computer Science IF=1</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In this work, we
                                focus on improving the anomaly detection performance by leveraging the forecasting error
                                patterns generated from prediction models, such as Sequence-to-Sequence (seq2seq),
                                Mixture Density Networks (MDNs), and Recurrent Neural Networks (RNNs). To this end, we
                                introduce Self-Organizing Map-based Anomaly Detector (SOMAD), an anomaly detection
                                framework based on a novel test statistic, SomAnomaly, for Cyber-Physical System (CPS)
                                security.

                            </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.google.com/search?q=Revitalizing+Self-Organizing+Map%3A+Anomaly+Detection+using+Forecasting+Error+Patterns&oq=Revitalizing+Self-Organizing+Map%3A+Anomaly+Detection+using+Forecasting+Error+Patterns&aqs=chrome..69i57.216j0j7&sourceid=chrome&ie=UTF-8">paper</a>][<a
                                    href="https://www.google.com/search?q=Revitalizing+Self-Organizing+Map%3A+Anomaly+Detection+using+Forecasting+Error+Patterns&oq=Revitalizing+Self-Organizing+Map%3A+Anomaly+Detection+using+Forecasting+Error+Patterns&aqs=chrome..69i57.216j0j7&sourceid=chrome&ie=UTF-8">project
                                    page</a>] </small> </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="rsom.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>




    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>TAR: Generalized Forensic Framework to Detect Deepfakes using Weakly Supervised
                                Learning</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Sangyup Lee,
                                    Shahroz Tariq, Junyaup Kim, and <b>Simon S. Woo*</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>36th
                                    International Conference on ICT Systems Security and Privacy Protection – IFIP SEC
                                    2021, 22–24 June 2021 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>BK Computer Science IF=1</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> This work introduces
                                a practical digital forensic tool to detect different types of deepfakes simultaneously
                                and proposes Transfer learning-based Autoencoder with Residuals (TAR). The ultimate goal
                                of this work is to develop an uni fied model to detect various types of deepfake videos
                                with high accuracy, with only a small number of training samples that can work well in
                                real-world settings. To achieve this, this work develops an autoencoder-based detection
                                model with Residual blocks and sequentially performs transfer learning to detect
                                different types of deepfakes simultaneously. The detection model shows a high detection
                                performance not only on the FF++ dataset but also on 200 real-world Deepfake-in-the-wild
                                videos. </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.google.com/search?q=Towards+a+Generalized+Framework+to+Detect+Deepfakes+using+Weakly+Supervised+Learning&oq=Towards+a+Generalized+Framework+to+Detect+Deepfakes+using+Weakly+Supervised+Learning&aqs=chrome..69i57.941j0j7&sourceid=chrome&ie=UTF-8">paper</a>][<a
                                    href="https://www.google.com/search?q=Towards+a+Generalized+Framework+to+Detect+Deepfakes+using+Weakly+Supervised+Learning&oq=Towards+a+Generalized+Framework+to+Detect+Deepfakes+using+Weakly+Supervised+Learning&aqs=chrome..69i57.941j0j7&sourceid=chrome&ie=UTF-8">project
                                    page</a>] </small> </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="tgddw.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>




    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Detecting Handcrafted Facial Image Manipulations and GAN-Generated Facial Images using
                                ShallowNet </b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Sangyup Lee,
                                    Shahroz Tariq, Youjin Shin, and <b>Simon S. Woo*</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Elsevier Applied
                                    Soft Computing, accepted on Feb 2021 </b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>SCIE Q1 IF=5.47</font>
                                </b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small>In this work, we introduce a novel Handcrafted Facial Manipulation (HFM) image dataset and soft computing neural network models (Shallow-FakeFaceNets) with an efficient facial manipulation detection pipeline. Our neural network classifier model, Shallow-FakeFaceNet (SFFN), shows the ability to focus on the manipulated facial landmarks to detect fake images. This study is targeted for developing an automated defense mechanism to combat fake images used in different online services and applications, leveraging our state-of-the-art handcrafted fake facial dataset (HFM) and the neural network classifier Shallow-FakeFaceNet (SFFN).</small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.sciencedirect.com/science/article/pii/S1568494621001794">paper</a>][<a
                                    href="https://www.sciencedirect.com/science/article/pii/S1568494621001794">project
                                    page</a>] </small> </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="dhfi.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>


    <div style="display: flex;flex-direction: row;justify-content: space-between;">

        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Exploring Racial Bias in Classifiers for Face Recognition</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Jaeju An,
                                    Jeongho Kim, Bosung Yang, Geonwoo Park, <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Third Workshop
                                    on Fairness, Accountability, Transparency, Ethics and Society on the Web (FATES)
                                    Joint with The Web Conference 2021, Ljubljana, Slovenia, </b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Recent advancements
                                in deep learning have allowed, among others,various applications of face recognition
                                systems, where a largeamount of face image data are typically required for training.
                            </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://arxiv.org/abs/2004.08945">paper</a>][<a
                                    href="https://arxiv.org/abs/2004.08945">project page</a>]  [<a
                                    href="https://www.youtube.com/watch?v=tgQ9TQc2jdU">video</a>]</small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="ExploringRacialBias.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>One Detector to Rule Them All: Towards a General Deepfake Attack Detection
                                Framework</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Shahroz Tariq,
                                    Sangyup Lee, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 30th Web
                                    Conference (WWW), Ljubljana, Slovenia, April 19, 2021 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='blue'><u>BK Computer Science IF=4, Acceptace rate = 20.6%</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> ... </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] [<a href="https://www.youtube.com/watch?v=RV_jA5lS7Ws">video</a>]</small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="odtr.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>


    <div style="display: flex;flex-direction: row;justify-content: space-between;">



        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>A Security Analysis of Blockchain-based DID Services</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Bong Gon Kim,
                                    Young-Seob Cho, Seok-hyun Kim, Hyoungshick Kim, and <b>Simon S. Woo</b> </i>
                            </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> IEEE Access, Jan
                                    2021 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>SCIE Q1 IF=4.09</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Decentralized
                                identifiers (DID) has shown great potential for sharing user identities across different
                                domains and services without compromising user privacy. DID is designed to enable the
                                minimum disclosure of the proof from a user’s credentials on a need-to-know basis with a
                                contextualized delegation. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://ieeexplore.ieee.org/document/9336711">paper</a>][<a
                                    href="https://ieeexplore.ieee.org/document/9336711">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="secBlock.jpg" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>BertLoc: Duplicate Location Record Detection in a Large-Scale Location Dataset</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Sujin Park,
                                    Sangwon Lee, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> SAC: The 36th
                                    ACM/SIGAPP Symposium On Applied Computing, Gwangju, Korea, 2021. </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='blue'><u>BK Computer Science IF=1</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In this work, we
                                propose BertLoc, a novel deep learning-based architecture to detect the duplicate
                                location represented in different ways (e.g., Cafe vs. Coffee House) and effectively
                                merge them into a single and consistent location record. BertLoc is based on
                                Multilingual Bert Model followed by BiLSTM and CNN to effectively compare and determine
                                whether given location strings are the same location or not. We evaluate BertLoc trained
                                with more than half a million location data used in real service in South Korea and
                                compare the results with other popular baseline methods. Our experimental results show
                                that BertLoc outperforms other popular baseline methods with 0.952 F1-score, and shows
                                great promise in detecting duplicate records in a large-scale location dataset. </small>
                        </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3412841.3441969">paper</a>][<a href="https://dl.acm.org/doi/10.1145/3412841.3441969">project page</a>] 
                                    [<a
                                    href="https://www.youtube.com/watch?v=zYsJigpb_jc">talk</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="bertLoc.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>



    <h4 style="margin-top:40px"><b>2020</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Image hashing algorithm to defend FGSM attacks on Neural Network</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Junyaup Kim,
                                    Siho Han and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Cyber Defence
                                    Next Generation Technology and Science Conference.(2020), March 2020 </b> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In this research, we
                                present a performance evaluation of existing image hashing algorithms on defending deep
                                learning models against adversarial attacks as an initial work to developing a new, time
                                efficient image hashing algorithm. Upon experimenting with existing image hashing
                                algorithms, we conclude that the wavelet hashing algorithm achieves the highest accuracy
                                (75%) when detecting images generated from Neural Networks attacked by the FGSM, with a
                                time complexity of 𝑂(𝑁). </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="jy.pdf">paper</a>][<a
                                    href="https://www.google.com/search?q=Image+hashing+algorithm+to+defend+FGSM+attacks+on+Neural+Network&oq=Image+hashing+algorithm+to+defend+FGSM+attacks+on+Neural+Network&aqs=chrome..69i57.4633j0j7&sourceid=chrome&ie=UTF-8">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="jy.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>


    <div style="display: flex;flex-direction: row;justify-content: space-between;">
        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>오픈소스 기반 격자 방식 PQC 알고리즘 분석 (Open-Source Code Analysis on
                                Lattice-Based Post Quantum Cryptography)</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Minha Kim,
                                    Hakjun Moon and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>CISC-W, 2020 </b>
                            </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Currently used
                                cryptography algorithms like RSA are vulnerable to quantum computers and are at risk of
                                being deciphered in polynomial time. As the commercialization of quantum computers is
                                soon to be realized, there is an urgent need for developing post-quantum
                                cryptography(PQC) algorithms. In this paper, we analyze several lattice-based PQC
                                algorithms from NIST Post-Quantum Cryptography Standardization project and test them in
                                some representative security protocols to show their practicality. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="pqc.pdf">paper</a>][<a
                                    href="https://www.google.com/search?q=%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4+%EA%B8%B0%EB%B0%98+%EA%B2%A9%EC%9E%90+%EB%B0%A9%EC%8B%9D+PQC+%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98+%EB%B6%84%EC%84%9D&rlz=1C1YKST_koKR876KR876&oq=%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4+%EA%B8%B0%EB%B0%98+%EA%B2%A9%EC%9E%90+%EB%B0%A9%EC%8B%9D+PQC+%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98+%EB%B6%84%EC%84%9D&aqs=chrome.0.69i59j69i60.422j0j7&sourceid=chrome&ie=UTF-8">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="pqc.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">
        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Compensating for the Lack of Extra Training Data by Learning Extra Representation</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Hyeonseong Jeon,
                                    Siho Han, Sangwon Lee and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 15th Asian
                                    Conference on Computer Vision (ACCV), Kyoto, Japan, 2020 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science IF=1</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> We introduce a novel
                                framework, Extra Representation (ExRep), to surmount the problem of not having access to
                                the JFT-300M data by instead using ImageNet and the publicly available model that has
                                been pre-trained on JFT-300M. We take a knowledge distillation approach, treating the
                                model pre-trained on JFT-300M as well as on ImageNet as the teacher network and that
                                pre-trained only on ImageNet as the student network. Our proposed method is capable of
                                learning additional representation effects of the teacher model, bolstering the student
                                model’s performance to a similar level to that of the teacher model, achieving high
                                classification performance even without extra training data. </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://openaccess.thecvf.com/content/ACCV2020/html/Jeon_Compensating_for_the_Lack_of_Extra_Training_Data_by_Learning_ACCV_2020_paper.html">paper</a>][<a
                                    href="https://openaccess.thecvf.com/content/ACCV2020/supplemental/Jeon_Compensating_for_the_ACCV_2020_supplemental.pdf">supplementary</a>][<a
                                    href="https://github.com/cutz-j/ExRep">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="ctle.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>ITAD: Integrative Tensor-based Anomaly Detection System for Reducing False Postives of
                                Satellite Systems</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Youjin Shin,
                                    Shahroz Tariq, Sangyup Lee, Myeong Shin Lee, Okchul Jung, Daewon Chung, and <b>Simon
                                        S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> CIKM ’20: The
                                    29th ACM International Conference on Information and Knowledge Management, Galway,
                                    Ireland </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science IF=3</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Reducing false
                                positives while detecting anomalies is of growing importance for various industrial
                                applications and mission-critical infrastructures, including satellite systems.
                                Undesired false positives can be costly for such systems, bringing the operation to a
                                halt for human experts to determine if the anomalies are true anomalies that need to be
                                mitigated </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/abs/10.1145/3340531.3412716">paper</a>][<a
                                    href="https://dl.acm.org/doi/abs/10.1145/3340531.3412716">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="itad.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Who is Delivering My Food? Detecting Food Delivery Abusers using Variational Reward
                                Inference Networks</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> DaeYoung Yoon
                                    and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> CIKM ’20: The
                                    29th ACM International Conference on Information and Knowledge Management, Galway,
                                    Ireland </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science IF=3</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> The recent paramount
                                success of the gig economy has introduced new business opportunities in different areas
                                such as food delivery service. However, there are food delivery ride abusers who break
                                the company rule by driving unauthorized vehicles that are not stated in the contract
                            </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3340531.3412750">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3340531.3412750">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="yoon.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Can We Create a Cross-Domain Federated Identity for Industrial Internet of Things without
                                Google?</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Eunsoo Kim,
                                    Young-Seob Cho, Bedeuro Kim, Woojoong Ji, Seok-hyun Kim and <b>Simon S. Woo</b> </i>
                            </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> IEEE Internet of
                                    Things Magazine, 2020 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Providing a
                                cross-domain federated identity is essential for next-generation Internet services
                                because information about user identity should be seamlessly exchanged across different
                                domains for authentication and authorization. </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://ieeexplore.ieee.org/document/9319620">paper</a>][<a
                                    href="https://ieeexplore.ieee.org/document/9319620">project page</a>] </small> </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="bc.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Applying Deep Learning to Reconstruct Pottery from Thousands Shards,</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Keeyoung Kim,
                                    Jinseok Hong, Sang-Hoon Rhee and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> ECML-PKDD,
                                    Ghent, Belgium 2020 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>Acceptance Rate=28%</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] </small> </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>OC-FakeDect: Classifying Deepfakes Using One-class Variational Autoencoder</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Hasam Khalid and
                                    <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> IEEE Biometrics
                                    Council newsletter</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> An image forgery
                                method called Deepfakes can cause security and privacy issues by changing the identity
                                of a person in a photo through the replacement of his/her face with a computer-generated
                                image or another person’s face. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="http://ieee-biometrics.org/images/pdf/Vol35-Newsletter.pdf">letter</a>][<a
                                    href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w39/Khalid_OC-FakeDect_Classifying_Deepfakes_Using_One-Class_Variational_Autoencoder_CVPRW_2020_paper.pdf">paper</a>]
                                    [<a href="https://fb.watch/5v0wiOGnsg/">talk</a>]
                                </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="ocvae.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Forecasting Error Pattern-based Anomaly Detection in Multivariate Time Series</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Seoyoung Park*,
                                    Siho Han* and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> ECML-PKDD,
                                    Ghent, Belgium 2020 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>Acceptance Rate=28%</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> We propose novel
                                Functional Data Analysis (FDA) and Autoencoder-based approaches for anomaly detection in
                                the Secure Water Treatment (SWaT) dataset, which realistically represents a scaled-down
                                industrial water treatment plant. We demonstrate that our methods can capture the
                                underlying forecasting error patterns of the SWaT dataset generated by Mixture Density
                                Networks (MDNs). </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.researchgate.net/publication/349556890_Forecasting_Error_Pattern-Based_Anomaly_Detection_in_Multivariate_Time_Series">paper</a>][<a
                                    href="https://www.researchgate.net/publication/349556890_Forecasting_Error_Pattern-Based_Anomaly_Detection_in_Multivariate_Time_Series">project
                                    page</a>] [<a
                                    href="https://slideslive.com/38932309/forecasting-error-patternbased-anomaly-detection-in-multivariate-time-series?ref=speaker-39040-latest">video</a>]</small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="fepb.jpg" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>국내 딥페이크 기술 현황 및 제도적 대응방안 연구</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Sowon Jeon,
                                    Junhyung Kang, Jinhee Hwang and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> CISC-S, 2020
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>우수논문상</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> 최근 한국에서 ‘가짜 연예인 음란
                                동영상’ 및 ‘지인 능욕’에 사용되는 딥페이크(Deepfakes) 포르노 문제가 사회적인 이슈로 불거지고 있다. 딥페이크 기술은 인공지능 기술의 발전에 맞추어
                                더욱더 빠르게 발전하고 있으나 관련 규제와 대응방안이 부족한 실정이다. 따라서 본 논문에서는 딥페이크 기술의 현황과 딥페이크 관련 국내외 법적 규제 및
                                현행법의 한계점을 살펴보고, 이로부터 각 개인 및 기관의 역할과 대응방안을 제안한다. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="sowon1.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>T-GD: Transferable GAN-generated Images Detection Framework</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Hyeonseong Jeon,
                                    Youngoh Bang, Junyaup Kim, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Thirty-seventh
                                    International Conference on Machine Learning (ICML), Vienna, Austria, 2020 </b>
                            </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>BK Computer Science IF=4, Acceptance Rate=18.48%</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In this work, we
                                present the Transferable GAN-images Detection framework (T-GD), a robust transferable
                                framework for an effective detection of GAN-images. T-GD is composed of a teacher and a
                                student model that can iteratively teach and evaluate each other to improve the
                                detection performance. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://arxiv.org/abs/2008.04115">paper</a>][<a
                                    href="https://arxiv.org/abs/2008.04115">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="tgd.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Real Time Localized Air Quality Monitoring and Prediction Through Mobile and Fixed IoT
                                Sensing Network</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Dan Zhang, and
                                    <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> IEEE Access, May
                                    2020 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>SCIE Q1 IF=4.09</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Air pollution and
                                its harm to human health has become a serious problem in many cities around the world.
                                In recent years, research interests in measuring and predicting the quality of air
                                around people has spiked. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://ieeexplore.ieee.org/document/9090830">paper</a>][<a
                                    href="https://ieeexplore.ieee.org/document/9090830">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>CAN-ADF: The Controller Area Network Attack Detection Framework</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Shahroz Tariq,
                                    Sangyup Lee, Huy Kang Kim, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Elsevier
                                    Computers & Security, December 2020 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>SCIE Q1 IF=3.58</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In recent years,
                                there has been significant interest in developing autonomous vehicles such as
                                self-driving cars. In-vehicle communications, due to simplicity and reliability, a
                                Controller Area Network (CAN) bus is widely used as the de facto standard to provide
                                serial communications between Electronic Control Units (ECUs) </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.sciencedirect.com/science/article/pii/S0167404820301292#:~:text=In%20this%20work%2C%20we%20propose,system%20for%20a%20CAN%20bus.&text=Our%20detection%20algorithm%20achieves%20accurate,CAN%20datasets%2C%20outperforming%20prior%20approach.">paper</a>][<a
                                    href="https://www.sciencedirect.com/science/article/pii/S0167404820301292#:~:text=In%20this%20work%2C%20we%20propose,system%20for%20a%20CAN%20bus.&text=Our%20detection%20algorithm%20achieves%20accurate,CAN%20datasets%2C%20outperforming%20prior%20approach.">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="canadf.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>OC-FakeDect: Classifying Deepfakes Using One-class Variational Autoencoder</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Hasam Khalid and
                                    <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Workshop on
                                    Media Forensics, CVPR 2020, Monday, 15th June 2020, Seattle, USA </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> An image forgery
                                method called Deepfakes can cause security and privacy issues by changing the identity
                                of a person in a photo through the replacement of his/her face with a computer-generated
                                image or another person’s face. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w39/Khalid_OC-FakeDect_Classifying_Deepfakes_Using_One-Class_Variational_Autoencoder_CVPRW_2020_paper.pdf">paper</a>][<a
                                    href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w39/Khalid_OC-FakeDect_Classifying_Deepfakes_Using_One-Class_Variational_Autoencoder_CVPRW_2020_paper.pdf">project
                                    page</a>] [<a href="https://fb.watch/5v0wiOGnsg/">talk</a>]</small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="ocvae.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Design and Evaluation of Enumeration Attacks on Package Tracking Systems</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Hanbin Jang,
                                    Woojung Ji, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 25th
                                    Australasian Conference on Information Security and Privacy, Perth, Australia, 2020
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>Acceptance rate ~ = 20%</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Most shipping
                                companies provide a package tracking system where customers can easily track their
                                package delivery status when the package is being shipped. However, we present a
                                security problem called enumeration attacks against package tracking systems...</small>
                        </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://link.springer.com/chapter/10.1007/978-3-030-55304-3_28">paper</a>][<a
                                    href="https://link.springer.com/chapter/10.1007/978-3-030-55304-3_28">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>How do we Create a Fantabulous Password?</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 29th Web
                                    Conference (WWW), Taipei, Taiwan, 2020 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science IF=4, Acceptance Rate=19%</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> </small> Although
                            pronounceability can improve password memorability, most existing password generation
                            approaches have not properly integrated the pronounceability of passwords in their designs.
                            In this work, we demonstrate several shortfalls of current pronounceable password generation
                            approaches, and then propose, ProSemPass, a new method of generating passwords that are
                            pronounceable and semantically meaningful. </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3366423.3380222">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3366423.3380222">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>I've Got Your Packages: Harvesting customers' delivery order data using package tracking
                                number enumeration attacks</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>,Hanbin Jang, Woojung Ji and Hyoungshick Kim </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 29th Web
                                    Conference (WWW), Taipei, Taiwan, 2020 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science IF=3, Acceptance Rate=19%</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> A package tracking
                                number (PTN) is widely used to monitor and track a shipment. Through the lenses of
                                security and privacy, however, a package tracking number can possibly reveal certain
                                personal information, leading to security and privacy breaches. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3366423.3380062">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3366423.3380062">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>FDFtNet: Facing Off Fake Images using Fake DetectionFine-tuning Network</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Hyeonseong
                                        Jeon, Youngoh Bang, and Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> SEC 2020
                                    International Conference on Information Security and Privacy Protection (IFIP-SEC),
                                    Solvenia, Sept 2020</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science IF=1</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Creating fake images
                                and videos such as "Deepfake" has become much easier these days due to the advancement
                                in Generative Adversarial Networks (GANs). Moreover, recent research such as the
                                few-shot learning can create highly realistic personalized fake images with only a few
                                images.</small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://arxiv.org/abs/2001.01265">paper</a>][<a
                                    href="https://arxiv.org/abs/2001.01265">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>How do we Create a Fantabulous Password?</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Joon Kuy
                                    Han,<b>Simon S. Woo</b>, and Hyoungshick Kim </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> ASIACCS: The
                                    13th ACM Asia Conference on Computer and Communications Security, Taipei, Taiwan,
                                    2020.</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science IF=1</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Designing a fallback
                                authentication mechanism that is both memorable and strong is a challenging problem
                                because of the trade-off between usability and security. Security questions are
                                popularly used as a fallback authentication method for password recovery. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3366423.3380222">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3366423.3380222">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Tale of Two Browsers: Understanding Users' Web Browser Choices in South Korea</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Jihye Woo, Ji
                                    Won Choi, Soyoon Jeon, Joon Han, Hyoungshick Kim, and <b>Simon S. Woo</b> </i>
                            </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> AsiaUSEC, Feb.
                                    2020 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Internet users in
                                South Korea seem to have clearly different web browser choices and usage patterns
                                compared to the rest of the world, heavily using Internet Explorer (IE) or multiple
                                browsers.</small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://link.springer.com/chapter/10.1007/978-3-030-54455-3_1">paper</a>][<a
                                    href="https://link.springer.com/chapter/10.1007/978-3-030-54455-3_1">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>CANTransfer: Transfer Learning based Intrusion Detection on a Controller Area Network
                                using Convolutional LSTM Network</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Shahroz Tariq,
                                    Sangyup Lee, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 35th
                                    ACM/SIGAPP Symposium On Applied Computing (SAC), Brno, Czech Republic, March 2020
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science IF=1</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In-vehicle
                                communications, due to simplicity and reliability, a Controller Area Network (CAN) bus
                                is widely used as the de facto standard to provide serial communications between
                                Electronic Control Units (ECUs). </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3341105.3373868">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3341105.3373868">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="cantransfer.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <h4 style="margin-top:40px"><b>2019</b></h4>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Designing for fallible humans</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Jelena Mirkovic
                                    and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 2019 IEEE Humans
                                    and Cyber Security (HACS) workshop in conjunction with IEEE CogMI (Cognitive Machine
                                    Intelligence), IEEE CIC (Collaboration and Internet Computing) and IEEE TPS (Trust,
                                    Privacy and Security of Intelligence Systems, and Applications) Los Angeles,
                                    California, USA, December 14, 2019.</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Security and privacy
                                solutions today are designed with an assumption of a rational user. System designers
                                assume that the user is able to review all information shown to them, consider it along
                                with other information they have, and user priorities, and make a conscious, rational
                                decision in their best interest. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://ieeexplore.ieee.org/document/8998513">paper</a>][<a
                                    href="https://ieeexplore.ieee.org/document/8998513">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Poster: Classifying Genuine Face images from Disguised Face Images</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Junyaup Kim,
                                    Siho Han, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 2019 IEEE
                                    International conference on Big Data (IEEE BigData 2019), Los Angeles, CA, USA</b>
                            </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In this preliminary
                                work, we aim to detect a target person's face from different similar individuals,
                                Doppelgangers, leveraging the dataset from Disguised Faces in the Wild (DFW) 2018. We
                                use well-known off-the-shelf face detection classifiers, such as ShallowNet, VGG-16, and
                                Xception to evaluate the classification performance. In order to further improve the
                                detection performance, we apply data augmentation. Our preliminary result shows that the
                                Xception model can classify one from different individuals with a 62% accuracy. </small>
                        </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://ieeexplore.ieee.org/abstract/document/9005683">paper</a>][<a
                                    href="https://ieeexplore.ieee.org/abstract/document/9005683">project page</a>]
                            </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="cgfi.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Poster: Nickel to Lego: Using Foolgle to Create Adversarial Examples to fool Google Cloud
                                Speech-to-Text API,</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Joon Kuy Han,
                                    Hyoungshick Kim and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 26th ACM
                                    Conference on Computer and Communications Security, London, UK, 2019</b> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Many companies offer
                                automatic speech recognition or Speech-to-Text APIs for use in diverse applications.
                                However, audio classification algorithms trained with deep neural networks (DNNs) can
                                sometimes misclassify adversarial examples, posing a significant threat to critical
                                applications. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3319535.3363264">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3319535.3363264">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Deep Learning for Blast Furnaces: Skip-Dense Layers Deep Learning Model to Predict the
                                Remaining Time to Close Tap-holes for Blast Furnaces</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Keeyoung Kim,
                                    Byeongrak Seo, Sang-Hoon Rhee, Seungmoon Lee, and <b>Simon S. Woo</b> </i> </small>
                        </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> CIKM'19,
                                    Beijing, China, Nov, 2019</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>Acceptance rate=21%, BK Computer Science IF=3</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Manufacturing steel
                                requires extremely challenging industrial processes. In particular, predicting the exact
                                time instance of opening and closing tap-holes in a blast furnace has a great influence
                                on steel production efficiency and operating cost, in addition to human safety. </small>
                        </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3357384.3357803">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3357384.3357803">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>FakeTalkerDetect: Effective and Practical Realistic Neural Talking Head Detection with a
                                Highly Unbalanced Datase</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Hyeonseong Jeon,
                                    Youngoh Bang, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 10th
                                    International Workshop on Human Behavior Understanding (HBU), held in conjunction
                                    with ICCV'19 Nov, 2019 - Seoul, S. Korea</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Detecting realistic
                                fake images and videos is an increasingly important and urgent problem because they can
                                be
                                maliciously used. In this work, we propose FakeTalkerDetect, which is based on siamese
                                networks to detect the recently proposed realistic talking head with few-shot learning.
                            </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.researchgate.net/publication/338187408_FakeTalkerDetect_Effective_and_Practical_Realistic_Neural_Talking_Head_Detection_with_a_Highly_Unbalanced_Dataset">paper</a>][<a
                                    href="https://www.researchgate.net/publication/338187408_FakeTalkerDetect_Effective_and_Practical_Realistic_Neural_Talking_Head_Detection_with_a_Highly_Unbalanced_Dataset">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Tensor Decomposition for Anomaly Detection in Space</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Youjin Shin,
                                    Sangyup Lee, Shahroz Tariq, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Workshop on
                                    Tensor Methods for Emerging Data Science Challenges (TMEDSC), held in conjunction
                                    with KDD'19 Aug 5, 2019 - Anchorage, Alaska, USA</b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://milets19.github.io/papers/milets19_poster_6.pdf">paper</a>][<a
                                    href="https://milets19.github.io/papers/milets19_poster_6.pdf">project page</a>]
                            </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="tdfad.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Contextual Anomaly Detection by Correlated Probability Distributions using
                                Kullback-Leibler Divergence</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Jinwoo Cho,
                                    Shahroz Tariq, Sangyup Lee, Young Geun Kim, Jeong-Han Yun, Jonguk Kim, Hyoung Chun
                                    Kim and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 5th Workshop on
                                    Mining and Learning from Time Series, held in conjunction with KDD'19 Aug 5, 2019 -
                                    Anchorage, Alaska, USA</b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3292500.3330776">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3292500.3330776">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="cad.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Detecting Anomalies in Space using Multivariate Convolutional LSTM with Mixtures of
                                Probabilistic PCA</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Shahroz Tariq,
                                    Sangyup Lee, Youjin Shin, Myeong Shin Lee, Okchul Jung, Daewon Chung, and <b>Simon
                                        S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> ACM SIG KDD,
                                    Alaska, USA, 2019.</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science IF=4</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Detecting an anomaly
                                is not only important for many terrestrial applications on Earth but also for space
                                applications. Especially, satellite missions are highly risky because unexpected
                                hardware and software failures can occur due to sudden or unforeseen space environment
                                changes. </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] </small> </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="dais.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Understanding Users Risk Perceptions about Personal Health Records Shared on Social
                                Networking Services</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Yuri Son,
                                    Geumhwan Cho, Hyoungshick Kim and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> ASIACCS: The
                                    12th ACM Asia Conference on Computer and Communications Security, Auckland, New
                                    Zealand, 2019</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science IF=1, Acceptance Rate = 22.5%</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> To understand users'
                                risk perceptions about sharing their PHR on SNS, we first conducted a qualitative user
                                study by interviewing 16 participants. Next, we conducted a large-scale online user
                                study with 497 participants in the U.S. to validate our qualitative results from the
                                first study. </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3321705.3329838">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3321705.3329838">project page</a>] </small>
                        </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>You Walk, We Authenticate: Lightweight Seamless Authentication based on Gait in Wearable
                                IoT Systems</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Pratik Musale,
                                    Duin Baek, Nuwan Werellagama, <b>Simon S. Woo</b>, and and Bong Jun Choi </i>
                            </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> IEEE Access,
                                    Early Access, 2019</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>SCIE Q1 IF= 3.557</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> With a plethora of
                                wearable IoT devices available today, we can easily monitor human activities, many of
                                which are unconscious or subconscious. Interestingly, some of these activities exhibit
                                distinct patterns for each individual, which can provide an opportunity to extract
                                useful features for user authentication. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://ieeexplore.ieee.org/document/8672772">paper</a>][<a
                                    href="https://ieeexplore.ieee.org/document/8672772">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>What Is in Your Password? Analyzing Memorable and Secure Passwords using a Tensor
                                Decomposition</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Youjin Shin and
                                    <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The Web
                                    Conference (WWW), May 2019</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science 우수학회 IF=3, Acceptance Rate 19.9% </u>
                                    </font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In the past, there
                                have been several studies in analyzing password strength and structures. However, there
                                are still many unknown questions to understand what really makes passwords both
                                memorable and strong. In this work, we aim to answer some of these questions by
                                analyzing password dataset through the lenses of data science and machine learning
                                perspectives. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3308558.3313690">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3308558.3313690">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Using Episodic Memory for User Authentication</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, Le Xiao, Ron Artstein, Elsi Kaiser, and Jelena Mrikovic </i> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> ACM Transactions
                                    on Transactions on Privacy and Security (TOPS), January 2019</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>SCIE Q1 IF=2.1</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Passwords are widely
                                used for user authentication, but they are often difficult for a user to recall, easily
                                cracked by automated programs, and heavily reused. Security questions are also used for
                                secondary authentication. They are more memorable than passwords, because the question
                                serves as a hint to the user, but they are very easily guessed. We propose a new
                                authentication mechanism, called "life-experience passwords (LEPs)." </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3308992">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3308992">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>GAN is a Friend or Foe? A Framework to Detect Various Fake Face Images</b></a>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Shahroz Tariq,
                                    Sangyup Lee, Youjin Shin, Ho Young Kim, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> ACM SAC Cyprus
                                    April 2019</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK Computer Science 우수학회 IF=1, Acceptance Rate 25%</u>
                                    </font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Creating fake images
                                such as replacing one's face with other person's face has become much easier due to the
                                advancement of sophisticated image editing tools. In addition, Generative Adversarial
                                Networks (GANs) enable creating natural looking human faces. However, fake images can
                                cause many potential problems, as they can be misused to abuse information, hurt people,
                                and generate fake identification. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3297280.3297410">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3297280.3297410">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="ganfof.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <h4 style="margin-top:40px"><b>2018</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Design and Evaluation of 3D CAPTCHAs</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Elsevier
                                    Computers & Security, December 2018</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>SCIE Q1 IF=3.06</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Most current 2D
                                CAPTCHAs are vulnerable to automated character recognition attacks and the latest
                                attacks can successfully break the 2D text CAPTCHAs at a rate of more than 90%. In this
                                work, we present two novel 3D CAPTCHAs, which are more secure than current 2D text
                                CAPTCHAs against automated character recognition attacks. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.sciencedirect.com/science/article/pii/S0167404818301238">paper</a>][<a
                                    href="https://www.sciencedirect.com/science/article/pii/S0167404818301238">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Poster: Memorability and Security of Image and Text Integrated Authentication
                                System</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Joonkyu Han and
                                    <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 34th Annual
                                    Computer Security Applications Conference (ACSAC)</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>Puerto Rico, USA, 2018</font>
                                </b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Evaluating and Breaking Naver’s Audio CAPTCHA using Off-the-Shelf Speech-to-text
                                APIs</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Soyoon Jeon,
                                    Jihye Woo, Ji Won Choi, Hyoungshick Kim, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Conference on
                                    Information Security and Cryptography 2017 Winter (CISC-W 2018) Seoul, Korea,
                                    2018</b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Understanding Users’ Perception on Digital Certificate and Their Web Browser Usages in
                                Korea</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Jihye Woo,
                                    Soyoon Jeon, Ji Won Choi, Hyoungshick Kim, and <b>Simon S. Woo</b> </i> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Conference on
                                    Information Security and Cryptography 2017 Winter (CISC-W 2018) Seoul, Korea,
                                    2018</b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Password typographical error resilience in honey encryption</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> H. Choi, J.
                                    Jeong,<b>Simon S. Woo</b>, K. Kang, and J. Hur </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Elsevier
                                    Computers & Security, October 2018</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>SCIE Q1 IF=2.86</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Honey encryption
                                (HE) is a novel password-based encryption scheme that is secure against brute-force
                                attacks even if users’ passwords have min-entropy. However, in HE, decryption with an
                                incorrect key produces fake messages that appear valid. Hence, password typographical
                                errors may confuse even legitimate users. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.sciencedirect.com/science/article/pii/S0167404818311246#:~:text=Honey%20encryption%20(HE)%20is%20a,may%20confuse%20even%20legitimate%20users.">paper</a>][<a
                                    href="https://www.sciencedirect.com/science/article/pii/S0167404818311246#:~:text=Honey%20encryption%20(HE)%20is%20a,may%20confuse%20even%20legitimate%20users.">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Poster: Adversarial Product Review Generation with Word Replacements</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Yimin Zhu and
                                    <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 25th ACM
                                    Conference on Computer and Communications Security (CCS 2018), Toronto, USA,
                                    2018</b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Machine learning
                                algorithms including Deep Neural Networks (DNNs) have shown great success in many
                                different areas. However, they are frequently susceptible to adversarial examples, which
                                are maliciously crafted inputs to fool machine learning classifiers. On the other hand,
                                humans cannot distinguish between non-adversarial and adversarial inputs. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3243734.3278492">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3243734.3278492">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="aprg.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Detecting In-Vehicle CAN Message Attacks using Heuristics and RNNs</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Shahroz Tariq,
                                    Sangyup Lee, Huy Kang Kim, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 3rd
                                    International workshop on Information & Operational Technology (IT & OT) security
                                    systems (IOSec 2018), co-located with 21st International Symposium on Research in
                                    Attacks, Intrusions and Defenses (RAID 2018), Crete, Greece, Sept 2018 </b> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In vehicle
                                communications, due to simplicity and reliability, a Controller Area Network (CAN) bus
                                is used as the de facto standard to provide serial communication between Electronic
                                Control Units (ECUs). However, prior research reveals that several network-level attacks
                                can be performed on the CAN bus due to the lack of underlying security mechanism.
                            </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://link.springer.com/chapter/10.1007/978-3-030-12085-6_4">paper</a>][<a
                                    href="https://link.springer.com/chapter/10.1007/978-3-030-12085-6_4">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="dican.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Detecting Both Machine and Human Created Fake Face Images In the Wild</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Shahroz Tariq,
                                    Sangyup Lee, Youjin Shin, Ho Young Kim, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 2nd
                                    International Workshop on Multimedia Privacy and Security (MPS 2018), co-located
                                    with 25th ACM Conference on Computer and Communications Security (CCS 2018),
                                    Toronto, USA, 2018 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Due to the
                                significant advancements in image processing and machine learning algorithms, it is much
                                easier to create, edit, and produce high quality images. However, attackers can
                                maliciously use these tools to create legitimate looking but fake images to harm others,
                                bypass image detection algorithms, or fool image recognition classifiers. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3267357.3267367">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3267357.3267367">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="dbmh.png" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>GuidedPass: Guiding users to create both more memorable and strong passwords</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b> and and Jelena Mirkovic </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 21st
                                    International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2018),
                                    Crete, Greece, Sept 2018 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK우수학회 IF=2, Acceptance Rate 22.8% </u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Password meters and
                                policies are currently the only tools helping users to create stronger passwords.
                                However, such tools often do not provide consistent or useful feedback to users, and
                                their suggestions may decrease memorability of resulting passwords. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.researchgate.net/publication/327469039_GuidedPass_Helping_Users_to_Create_Strong_and_Memorable_Passwords_21st_International_Symposium_RAID_2018_Heraklion_Crete_Greece_September_10-12_2018_Proceedings">paper</a>][<a
                                    href="https://www.researchgate.net/publication/327469039_GuidedPass_Helping_Users_to_Create_Strong_and_Memorable_Passwords_21st_International_Symposium_RAID_2018_Heraklion_Crete_Greece_September_10-12_2018_Proceedings">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>

    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Poster: Leveraging Semantic Transformation to Investigate Password Habits and Their
                                Causes</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Ameya
                                    Hanesamgar, <b>Simon S. Woo</b>, Chris Kanich, and Jelena Mirkovic </i> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Usenix The
                                    Fourteenth Symposium on Usable Privacy and Security (SOUPS 2018), Baltimore, USA,
                                    2018 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> It is no secret that
                                users have difficulty choosing and remembering strong passwords, especially when asked
                                to choose different passwords across different accounts. While research has shed light
                                on password weaknesses and reuse, less is known about user motivations for following bad
                                password practices. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3173574.3174144">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3173574.3174144">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>When George Clooney is not George Clooney: Using GenAttack to Deceive Amazon’s and Naver’s
                                Celebrity Recognition APIs</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Keeyoung Kim and
                                    <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 33rd IFIP TC-11
                                    SEC 2018 International Conference on Information Security and Privacy Protection
                                    (IFIP-SEC), Poznan, Poland, Sept 2018 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK우수학회 IF=1, Acceptance Rate 36% </u>, Best Student Paper
                                        Nominated</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In recent years,
                                significant advancements have been made in detecting and recognizing contents of images
                                using Deep Neural Networks (DNNs). As a result, many companies offer image recognition
                                APIs for use in diverse applications. However, image classification algorithms trained
                                with DNNs can misclassify adversarial examples, posing a significant threat to critical
                                applications. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://link.springer.com/chapter/10.1007/978-3-319-99828-2_25">paper</a>][<a
                                    href="https://link.springer.com/chapter/10.1007/978-3-319-99828-2_25">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Generating Adversarial Images using Genetic Algorithm</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Keeyoung Kim and
                                    <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The Second
                                    International Workshop on The Bright and Dark Sides of Computer Vision: Challenges
                                    and Opportunities for Privacy and Security (CV-COPS2018) In conjunction with the
                                    IEEE CVPR 2018 , Salt Lake City, USA, June 2018 </b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.researchgate.net/publication/339840424_Generating_Adversarial_Images_using_Genetic_Algorithm">paper</a>][<a
                                    href="https://www.researchgate.net/publication/339840424_Generating_Adversarial_Images_using_Genetic_Algorithm">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Poster: I can’t hear this because I am human: A novel design of audio CAPTCHA
                                system</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Jusop Choi,
                                    Taekkyung Oh, William Aiken, <b>Simon S. Woo</b> and Hyoungshick Kim </i> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 11th ACM
                                    Asia Conference on Computer and Communications Security (ACM ASIACCS), Incheon,
                                    Korea, 2018 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> A CAPTCHA
                                (Completely Automated Public Turing test to tell Computers and Humans Apart) provides
                                the first line of defense to protect websites against bots and automatic crawling.
                                Recently, audio-based CAPTCHA systems are started to use for visually impaired people in
                                many internet services. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3196494.3201590">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3196494.3201590">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Benefits and Challenges of Long Term Self-Tracking to Prevent Lonely Deaths and Detect
                                Signs of Life</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> A Short Workshop
                                    on Next Steps Towards Long Term Self Tracking at ACM SIG CHI2018, April, 2018,
                                    Montreal, Canada </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> We explore the
                                benefit of a new long-term self-tracking application for the elderly population. In the
                                last few years, there has been a significant increase in number of people dying alone or
                                remaining undiscovered for a long period time in Korea and Japan. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="http://longtermtracking.offis.de/wp-content/uploads/2018/03/Woo.pdf">paper</a>][<a
                                    href="http://longtermtracking.offis.de/wp-content/uploads/2018/03/Woo.pdf">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Leveraging Semantic Transformation to Investigate Password Habits and Their Causes</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Ameya
                                    Hanesamgar, <b>Simon S. Woo</b>, Chris Kanich, and Jelena Mirkovic </i> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> ACM SIG CHI2018,
                                    April, 2018, Montreal, Canada </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u>BK우수학회 IF=4, Acceptance Rate 25.7%</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> It is no secret that
                                users have difficulty choosing and remembering strong passwords, especially when asked
                                to choose different passwords across different accounts. While research has shed light
                                on password weaknesses and reuse, less is known about user motivations for following bad
                                password practices. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/3173574.3174144">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/3173574.3174144">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Memorablity and Security of Different Passphrase Generation Methods</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, and Jelena Mirkovic </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Review of KIISC
                                    (정보보호학회지), Feb. 2018 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Passphrases are
                                considered to be more secure than passwords since they are longer than passwords.
                                However, users choose predictable word patterns and common phrases to make passphrases
                                memorable, which in turn significantly lowers security. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE07399563">paper</a>][<a
                                    href="https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE07399563">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Survey on Current Password Composition Policies</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, Kyeong Joo Jung, and Bong Jun Choi </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Review of KIISC
                                    (정보보호학회지), Feb. 2018 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Textual passwords
                                are widely used for accessing online accounts. Despite the problems of current textual
                                passwords, research has shown that there is no other strong alternatives for a textual
                                password due to its simplicity. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE07399565">paper</a>][<a
                                    href="https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE07399565">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>


    <h4 style="margin-top:40px"><b>2017</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Lightweight Authentication for IoT</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Pratik Musale,
                                    Duin Baek, <b>Simon S. Woo</b>, Bong Jun Choi </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Proc. ACM
                                    CoNEXT, Seoul, South Korea, Dec. 2017. (Student Workshop) </b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Toward Machine Generated Passwords</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, Wenzhi Li, and, Hyeran Jeon </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Conference on
                                    Information Security and Cryptography 2017 Winter (CISC-W), Seoul, Korea, Dec. 2017
                                    (Best paper (우수 논문상)) </b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Computer Vision Attacks against 3D CAPTCHAs</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The First
                                    International Workshop on The Bright and Dark Sides of Computer Vision: Challenges
                                    and Opportunities for Privacy and Security (CV-COPS2017) In conjunction with the
                                    IEEE CVPR 2017 , Honolulu, USA, July 2017 </b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Life-Experience Passwords (LEPs)</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, Jelena Mirkovic, Ron Artstein, and Elsi Kaiser </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Usenix The
                                    Thirteenteenth Symposium on Usable Privacy and Security (SOUPS 2017), Santa Clara,
                                    USA, July 2017 </b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/2991079.2991107">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/2991079.2991107">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <h4 style="margin-top:40px"><b>2016</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Improving Recall and Security of Passphrases Through Use of Mnemonics</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b> and Jelena Mirkovic </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Proceedings of
                                    the 10th International Conference on Passwords (Passwords), Bochum, Germany, 2016
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Passphrases are
                                regarded as more secure than passwords because they are longer than passwords. Yet,
                                users use predictable word patterns and common phrases to make passphrases memorable,
                                which in turn significantly lowers security. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.semanticscholar.org/paper/Improving-Recall-and-Security-of-Passphrases-Use-of-Woo-Mirkovic/308e48f46bdcde59f1224fe178d36bd242a542cd">paper</a>][<a
                                    href="https://www.semanticscholar.org/paper/Improving-Recall-and-Security-of-Passphrases-Use-of-Woo-Mirkovic/308e48f46bdcde59f1224fe178d36bd242a542cd">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Life Experience Passwords (LEPs)</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, Jelena Mirkovic, Elsi Kaiser, and Ron Artstein </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 32nd Annual
                                    Computer Security Applications Conference (ACSAC), Los Angeles, 2016 </b> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'><u> BK우수학회 IF=2, Acceptance Rate 22.8%</u></font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://dl.acm.org/doi/10.1145/2991079.2991107">paper</a>][<a
                                    href="https://dl.acm.org/doi/10.1145/2991079.2991107">project page</a>] </small>
                        </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Good Automatic Authentication Question Generation</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, Zuyao Li, and Jelena Mirkovic </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 9th SIGGEN
                                    International Natural Language Generation Conference (INLG), Edinburgh, 2016 </b>
                            </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> We explore a novel
                                application of Question Generation (QG) for authentication use, where questions are
                                widely used to verify user identity for online accounts. In our approach, we prompt
                                users to provide a few sentences about their personal life events. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.aclweb.org/anthology/W16-6632.pdf">paper</a>][<a
                                    href="https://www.aclweb.org/anthology/W16-6632.pdf">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Exploration of 3D Texture and Projection for New CAPTCHA Design</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, Jingul Kim, Duoduo Yu, and Beomjun Kim </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> The 17th World
                                    Conference on Information Security Applications (WISA), Jeju, 2016 </b> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>Best Conference Paper (우수논문상)</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Most of current
                                text-based CAPTCHAs have been shown to be easily breakable. In this work, we present two
                                novel 3D CAPTCHA designs, which are more secure than current 2D text CAPTCHAs, against
                                automated attacks. Our approach is to display CAPTCHA characters onto 3D objects to
                                improve security. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://link.springer.com/chapter/10.1007/978-3-319-56549-1_30">paper</a>][<a
                                    href="https://link.springer.com/chapter/10.1007/978-3-319-56549-1_30">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>



    <h4 style="margin-top:40px"><b>2015</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Empirical Data Analysis on User Privacy and Sentiment in Personal Blogs</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b> and Harsha Manjunatha </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 2nd ACM SIGIR
                                    Workshop on Privacy-Preserving Information Retrieval, Chilie, 2015 </b> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] </small> </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Engaging Novices in Cybersecurity Competitions: A Vision and Lessons Learned at ACM Tapia
                                2015</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Jelena Mirkovic,
                                    Aimee Tabor, <b>Simon S. Woo</b> and Portia Pusey </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> USENIX Summit on
                                    Gaming, Games, and Gamification in Security Education (3GSE), D.C, 2015 </b>
                            </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Cybersecurity
                                competitions are popular tools for attracting students to cybersecurity field. Yet, many
                                competitions require extensive preparation, strong coding skills and solid background
                                knowledge, not just in security, but also in system administration, networking and
                                operating systems. </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.usenix.org/conference/3gse15/summit-program/presentation/mirkovic">paper</a>][<a
                                    href="https://www.usenix.org/conference/3gse15/summit-program/presentation/mirkovic">project
                                    page</a>] </small> </p>
                    </tr>

                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>


    <h4 style="margin-top:40px"><b>2014</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Optimal application allocation on multiple public clouds</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b> and Jelena Mirkovic </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Elsevier
                                    Computer Networks, February 2014. </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>SCIE Q1 IF=2.52</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Cloud computing
                                customers currently host all of their application components at a single cloud provider.
                                Single-provider hosting eases maintenance tasks, but reduces resilience to failures.
                                Recent research (Li et al., 2010) also shows that providers’ offers differ greatly in
                                performance and price, and no single provider is the best in all service categories.
                            </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.sciencedirect.com/science/article/abs/pii/S1389128614000371">paper</a>][<a
                                    href="https://www.sciencedirect.com/science/article/abs/pii/S1389128614000371">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Life-Experice Passwords</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, Jelena Mikovic, Ron Artstein, and Elsi Kaiser </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Who are you?!
                                    Adventures in Authentication: ACM SOUPS-WAY Workshop, 2014, Menlo Park, CA </b>
                            </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Passwords are widely
                                used for user authentication, but they are often difficult for a user to recall, easily
                                cracked by automated programs and heavily reused. Security questions are also used for
                                secondary authentication. They are more memorable than passwords, but are very easily
                                guessed. We propose a new authentication mechanism, called "life-experience passwords
                                (LEPs)," which outperforms passwords and security questions, both at recall and at
                                security. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://cups.cs.cmu.edu/soups/2014/workshops/papers/lep_woo_12.pdf">paper</a>][<a
                                    href="https://cups.cs.cmu.edu/soups/2014/workshops/papers/lep_woo_12.pdf">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Poster: 3DOC: 3D Object CAPTCHA</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, and B. Kim </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Information
                                    Sciences Institute Graduate Student Symposium (ISI-GSS), Nov, 2014 (Best Student
                                    Paper) </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Current 2D CAPTCHA
                                mechanisms can be easily defeated by character recognition and segmentation attacks by
                                automated machines. Recently, 3D CAPTCHA schemes have been proposed to overcome the
                                weaknesses of 2D CAPTCHA for a few websites. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://openreview.net/forum?id=rkWY4b-dWS">paper</a>][<a
                                    href="https://openreview.net/forum?id=rkWY4b-dWS">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>3DOC: 3D Object CAPTCHA</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, and B. Kim </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> 23rd
                                    International World Wide Web (WWW) Conference, 2014 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Current 2D CAPTCHA
                                mechanisms can be easily defeated by character recognition and segmentation attacks by
                                automated machines. Recently, 3D CAPTCHA schemes have been proposed to overcome the
                                weaknesses of 2D CAPTCHA for a few websites. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.researchgate.net/publication/261961424_3DOC_3D_object_CAPTCHA">paper</a>][<a
                                    href="https://www.researchgate.net/publication/261961424_3DOC_3D_object_CAPTCHA">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Life Experience-Passwords</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, Jelena Mirkovic, and Elsi Kaiser </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Network and
                                    Distributed System Security (NDSS) Symposium, Feb, 2014 </b> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://cups.cs.cmu.edu/soups/2014/workshops/papers/lep_woo_12.pdf">paper</a>][<a
                                    href="https://cups.cs.cmu.edu/soups/2014/workshops/papers/lep_woo_12.pdf">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>


    <h4 style="margin-top:40px"><b>2011</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Analysis of Proximity-1 Space Link Interleaved Time Synchronization Protocol</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo*</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> IEEE Globecom
                                    2011, Houston, TX </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b>
                                    <font color='purple'>Acceptance rate: 36%</font>
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> To synchronize
                                clocks between spacecraft in proximity, the Proximity-1 Space Link Interleaved Time
                                Synchronization (PITS) Protocol has been proposed. PITS is based on the NTP Interleaved
                                On-Wire Protocol and is capable of being adapted and integrated into CCSDS Proximity-1
                                Space Link with minimal modifications. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://ieeexplore.ieee.org/document/6134144">paper</a>][<a
                                    href="https://ieeexplore.ieee.org/document/6134144">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>



    <h4 style="margin-top:40px"><b>2010</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>MACHETE: A Protocol Evaluation Tool for Space- Based Networking Architecture and
                                Simulation</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> E. Jennings, J.
                                    Segui, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> AIAA SpaceOps
                                    2010, Huntsville, AL </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Space Exploration
                                missions requires the design and implementation of space networking that differs from
                                terrestrial networks. In a space networking architecture, interplanetary communication
                                protocols need to be designed, validated and evaluated carefully to support different
                                mission requirements. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://arc.aiaa.org/doi/10.2514/6.2010-2260">paper</a>][<a
                                    href="https://arc.aiaa.org/doi/10.2514/6.2010-2260">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Space Time Distribution and Synchronization Protocol Development for Mars Proximity
                                Link</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, David Mills, and J. Gao </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> AIAA SpaceOps
                                    2010 (Invited for Book Chapter) </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Time distribution
                                and synchronization in deep space network are challenging due to long propagation
                                delays, spacecraft movements, and relativistic effects. Further, the Network Time
                                Protocol (NTP) designed for terrestrial networks may not work properly in space </small>
                        </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://arc.aiaa.org/doi/10.2514/6.2010-2360">paper</a>][<a
                                    href="https://arc.aiaa.org/doi/10.2514/6.2010-2360">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>


    <h4 style="margin-top:40px"><b>2009</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Space Communications and Navigation (SCaN) Network Simulation Tool Development and Its Use
                                Cases</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> E. Jennings, R.
                                    Borgen, C. Chevalier, E. Wesley, Sam Nguyen, John Segui, Tudor Stoenescu, Shin-Ywan
                                    Wang, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> AIAA, Modeling
                                    and Simulation Technologies (AIAA MST) Conference, 2009 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In this work, we
                                focus on the development of a simulation tool to assist in analysis of current and
                                future (proposed) network architectures for NASA. Specifically, the Space Communications
                                and Navigation (SCaN) Network is being architected as an integrated set of new assets
                                and a federation of upgraded legacy systems. The SCaN architecture for the initial
                                missions for returning humans to the moon and beyond will include the Space Network (SN)
                                and the Near-Earth Network (NEN). </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.researchgate.net/publication/268556870_Space_Communications_and_Navigation_SCaN_Network_Simulation_Tool_Development_and_Its_Use_Cases">paper</a>][<a
                                    href="https://www.researchgate.net/publication/268556870_Space_Communications_and_Navigation_SCaN_Network_Simulation_Tool_Development_and_Its_Use_Cases">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Efficient File Sharing by multicast - P2P protocol using network coding and rank based
                                peer selection</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b> and Tudor Stoenescu </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> IEEE 69th
                                    Vehicular Technology Conference (IEEE VTC) 2009-Spring, Barcelona, Spain, April,
                                    2009 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> In this work, we
                                consider information dissemination and sharing in a highly dynamic peer-to-peer (P2P)
                                communication network. In particular, we explore a network coding technique for
                                transmission and a rank based peer selection (RBPS) method for network formation.
                            </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://ieeexplore.ieee.org/document/5073526">paper</a>][<a
                                    href="https://ieeexplore.ieee.org/document/5073526">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <h4 style="margin-top:40px"><b>2008</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Interfacing Space Communications and Navigation Network Simulation with Distributed System
                                Integration Laboratories (DSIL)</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Esther H.
                                    Jennings, Sam P. Nguyen, Shin-Ywan Wang, and <b>Simon S. Woo</b> </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> AIAA SpaceOps
                                    2008 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> NASA’s planned Lunar
                                missions will involve multiple NASA centers where each participating center has a
                                specific role and specialization. In this vision, the Constellation program (CxP)’s
                                Distributed System Integration Laboratories (DSIL) architecture consist of multiple
                                System Integration Labs (SILs), with simulators, emulators, testlabs and control centers
                                interacting with each other over a broadband network to perform test and verification
                                for mission scenarios. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://arc.aiaa.org/doi/10.2514/6.2008-3462">paper</a>][<a
                                    href="https://arc.aiaa.org/doi/10.2514/6.2008-3462">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Prioritized LT codes</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b> and Mike Cheng </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> IEEE Annual
                                    Conference on Information Sciences and Systems (CISS), Princeton, NJ, March 2008.
                                </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> It is common in data
                                transmissions that some information is more important than others. This is especially
                                true in space communications where mission critical information or science data are high
                                priority. In this work, we propose a simple yet constructive scheme to send high
                                priority data reliably and efficiently using Luby transform (LT) codes. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://ieeexplore.ieee.org/document/4558589">paper</a>][<a
                                    href="https://ieeexplore.ieee.org/document/4558589">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>
    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>A Simulation Tool for ASCTA Microsensor Network Architecture</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b>, Esther Jennings, and Loren Clare </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> IEEE Aerospace
                                    Conference, Big Sky, MT, March, 2008 </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> Advances in
                                technology have made the large-scale deployment of low-cost networked sensors possible
                                for situational awareness. We developed a Simulation Tool for the Advanced Sensors
                                Collaborative Technology Alliance (ASCTA) Microsensor Network Architecture (STAMINA) to
                                evaluate the performance of networked sensor systems. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://ieeexplore.ieee.org/document/4526447">paper</a>][<a
                                    href="https://ieeexplore.ieee.org/document/4526447">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>

    </div>
    <hr>

    <h4 style="margin-top:40px"><b>2007</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>Improved In Situ Communications Using Network Coding</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> Mike Cheng,
                                    <b>Simon S. Woo</b>, Kar-Ming Cheung, Sam Dolinar, and Jon Hamkins </i> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> Research and
                                    Technology Development Poster session, (R&TD), Pasadena, Nov, 2007 </b> </small>
                        </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="">paper</a>][<a href="">project page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

    <h4 style="margin-top:40px"><b>2006</b></h4>
    <hr>

    <div style="display: flex;flex-direction: row;justify-content: space-between;">


        <div style="margin-left: 25px;margin-right: 10px;">
            <table>
                <thead>
                    <tr>
                        <a><b>CFDP Performance Over Weather-Dependent Ka-Band Channel</b></a>
                    </tr>
                </thead>
                <tbody>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <i> <b>Simon S.
                                        Woo</b> and Jay Gao </i> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> <b> AIAA SpaceOps
                                    2006, Rome, Italy </b> </small> </p>
                    </tr>
                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> This study presents
                                an analysis of the delay performance of the CCSDS File Delivery Protocol (CFDP) over
                                weather-dependent Ka-band channel. The Ka-band channel condition is determined by the
                                strength of the atmospheric noise temperature, which is weather dependent. </small> </p>
                    </tr>

                    <tr>
                        <p style="margin-top: 0px;margin-bottom: 0px;text-align: justify;"> <small> [<a
                                    href="https://www.researchgate.net/publication/255624199_CFDP_Performance_over_Weather-Dependent_Ka-band_Channel">paper</a>][<a
                                    href="https://www.researchgate.net/publication/255624199_CFDP_Performance_over_Weather-Dependent_Ka-band_Channel">project
                                    page</a>] </small> </p>
                    </tr>
                </tbody>
            </table>
        </div>
        <div class="col-lg-3" style="vertical-align: middle;display:flex;flex-direction:row;justify-content:center">
            <img src="" style="max-height:160px;width: 360px; margin-bottom:10px">
        </div>
    </div>
    <hr>

</div>
<!-- 
<div class="divider"></div>
<div class="section">
    <h5>2018</h5>
    <div class="row">
<p> Simon S. Woo*, "Design and Evaluation of 3D CAPTCHAs", Elsevier Computers & Security, December 2018 (<b><font color='purple'>SCIE Q1 IF=3.06</font></b>) </p>
        
<p> Joonkyu Han and Simon S. Woo*, "Poster: Memorability and Security of Image and Text Integrated Authentication System," The 34th Annual Computer Security Applications Conference (ACSAC), Puerto Rico, USA, 2018 </p>

<p> Soyoon Jeon, Jihye Woo, Ji Won Choi, Hyoungshick Kim, and Simon S. Woo*, "Evaluating and Breaking Naver’s Audio CAPTCHA using Off-the-Shelf Speech-to-text APIs," Conference on Information Security and Cryptography 2017 Winter (CISC-W 2018), Seoul, Korea, 2018 </p>

<p> Jihye Woo, Soyoon Jeon, Ji Won Choi, Hyoungshick Kim, and Simon S. Woo*, "Understanding Users’ Perception on Digital Certificate and Their Web Browser Usages in Korea," Conference on Information Security and Cryptography 2017 Winter (CISC-W 2018), Seoul, Korea, 2018 (Best Paper, 국보연 원장상) </p>

<p> H. Choi, J. Jeong, Simon S Woo, K. Kang, and J. Hur, "Password typographical error resilience in honey encryption", Elsevier Computers & Security, October 2018 (<b><font color='purple'>SCIE Q1 IF=2.86</font></b>) </p>

<p> Yimin Zhu and Simon S. Woo* "Poster: Adversarial Product Review Generation with Word Replacements," 25th ACM Conference on Computer and Communications Security (CCS 2018), Toronto, USA, 2018 </p>

<p> Shahroz Tariq, Sangyup Lee, Huy Kang Kim, and Simon S. Woo* <strong>"Detecting In-Vehicle CAN Message Attacks using Heuristics and RNNs",</strong> 3rd International workshop on Information & Operational Technology (IT & OT) security systems (IOSec 2018), co-located with 21st International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2018), Crete, Greece, Sept 2018 </p>

<p> Shahroz Tariq, Sangyup Lee, Youjin Shin, Ho Young Kim, and Simon S. Woo* <strong>"Detecting Both Machine and Human Created Fake Face Images In the Wild",</strong> 2nd International Workshop on Multimedia Privacy and Security (MPS 2018), co-located with 25th ACM Conference on Computer and Communications Security (CCS 2018), Toronto, USA, 2018 </p>

<p> Simon S. Woo* and Jelena Mirkovic "GuidedPass: Guiding users to create both more memorable and strong passwords", 21st International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2018), Crete, Greece, Sept 2018 (<b><font color='blue'>Acceptance Rate 22.8%, BK우수학회 IF=2</font></b>). </p>

<p> Ameya Hanesamgar, Simon S. Woo*, Chris Kanich, and Jelena Mirkovic, "Poster: Leveraging Semantic Transformation to Investigate Password Habits and Their Causes," Usenix The Fourteenth Symposium on Usable Privacy and Security (SOUPS 2018), Baltimore, USA, 2018 </p>

<p> Keeyoung Kim and Simon S. Woo*, "When George Clooney is not George Clooney: Using GenAttack to Deceive Amazon’s and Naver’s Celebrity Recognition APIs", 33rd IFIP TC-11 SEC 2018 International Conference on Information Security and Privacy Protection (IFIP-SEC), Poznan, Poland, Sept 2018 (<b><font color='blue'>Acceptance Rate 36%, BK우수학회 IF=1, Best Student Paper Nominated</font></b>). </p>

<p> Keeyoung Kim and Simon S. Woo*, "Generating Adversarial Images using Genetic Algorithm", The Second International Workshop on The Bright and Dark Sides of Computer Vision: Challenges and Opportunities for Privacy and Security (CV-COPS2018) In conjunction with the IEEE CVPR 2018 , Salt Lake City, USA, June 2018. </p>

<p> Jusop Choi, Taekkyung Oh, William Aiken, Simon S. Woo and Hyoungshick Kim, “Poster: I can’t hear this because I am human: A novel design of audio CAPTCHA system”, The 11th ACM Asia Conference on Computer and Communications Security (ACM ASIACCS), Incheon, Korea, 2018 </p>

<p> Simon S. Woo*, "Benefits and Challenges of Long Term Self-Tracking to Prevent Lonely Deaths and Detect Signs of Life," A Short Workshop on Next Steps Towards Long Term Self Tracking at ACM SIG CHI2018, April, 2018, Montreal, Canada (pdf) </p>

<p> Ameya Hanesamgar, Simon S. Woo*, Chris Kanich, and Jelena Mirkovic, "Leveraging Semantic Transformation to Investigate Password Habits and Their Causes," ACM SIG CHI2018, April, 2018, Montreal, Canada (<b><font color='blue'>Acceptance Rate 25.7%, BK우수학회 IF=4</font></b>)(pdf) </p>

<p> Simon S. Woo*, and Jelena Mirkovic, "Memorablity and Security of Different Passphrase Generation Methods,"Review of KIISC (정보보호학회지), Feb. 2018 (pdf) </p>

<p> Simon S. Woo*, Kyeong Joo Jung, and Bong Jun Choi, "Survey on Current Password Composition Policies,"Review of KIISC (정보보호학회지), Feb. 2018 (pdf) </p>
    </div>
</div>

<div class="divider"></div>
<div class="section">
    <h5>2017</h5>
    <div class="row">

<p> Pratik Musale, Duin Baek, Simon S. Woo, Bong Jun Choi, “Lightweight Authentication for IoT,” Proc. ACM CoNEXT, Seoul, South Korea, Dec. 2017. (Student Workshop) </p>

<p> Simon S. Woo, Wenzhi Li, and, Hyeran Jeon, “Toward Machine Generated Passwords,” Conference on Information Security and Cryptography 2017 Winter (CISC-W), Seoul, Korea, Dec. 2017 (Best paper (우수 논문상)) </p>

<p> Simon S. Woo*, "Computer Vision Attacks against 3D CAPTCHAs", The First International Workshop on The Bright and Dark Sides of Computer Vision: Challenges and Opportunities for Privacy and Security (CV-COPS2017) In conjunction with the IEEE CVPR 2017 , Honolulu, USA, July 2017 (pdf). </p>

<p> Simon S. Woo, Jelena Mirkovic, Ron Artstein, and Elsi Kaiser, "Life-Experience Passwords (LEPs)", Usenix The Thirteenteenth Symposium on Usable Privacy and Security (SOUPS 2017), Santa Clara, USA, July 2017. </p>
    </div>
</div>
<div class="divider"></div>
<div class="section">
    <h5>2016</h5>
    <div class="row">
<p> Simon S. Woo* and Jelena Mirkovic. <strong> "Improving Recall and Security of Passphrases Through Use of Mnemonics" </strong>, Proceedings of the 10th International Conference on Passwords (Passwords), Bochum, Germany, 2016 <a href="../../raw/master/Publications/Improving Recall and Security of Passphrases Through Use of Mnemonics.pdf" download> (PDF) </a>
 </p>

<p> Simon S. Woo, Jelena Mirkovic, Elsi Kaiser, and Ron Artstein "Life Experience Passwords (LEPs)", The 32nd Annual Computer Security Applications Conference (ACSAC), Los Angeles, 2016 (<b><font color='blue'>Acceptance Rate 22.8%, BK우수학회 IF=2</font></b>) (pdf) </p>

<p> Simon S. Woo*, Zuyao Li, and Jelena Mirkovic, "Good Automatic Authentication Question Generation", The 9th SIGGEN International Natural Language Generation Conference (INLG), Edinburgh, 2016 (pdf) </p>

<p> Simon S. Woo, Jingul Kim, Duoduo Yu, and Beomjun Kim, "Exploration of 3D Texture and Projection for New CAPTCHA Design", The 17th World Conference on Information Security Applications (WISA), Jeju, 2016 (Best Conference Paper) (pdf) </p>
     </div>
</div>
<div class="divider"></div>
<div class="section">
    <h5>2015</h5>
    <div class="row">
<p> Simon S. Woo and Harsha Manjunatha, "Empirical Data Analysis on User Privacy and Sentiment in Personal Blogs", 2nd ACM SIGIR Workshop on Privacy-Preserving Information Retrieval, Chilie, 2015 (pdf) </p>

<p> Jelena Mirkovic, Aimee Tabor, Simon S. Woo, and Portia Pusey, "Engaging Novices in Cybersecurity Competitions: A Vision and Lessons Learned at ACM Tapia 2015", 2015 USENIX Summit on Gaming, Games, and Gamification in Security Education (3GSE), D.C, 2015 (pdf) </p>
    </div>
</div>
<div class="divider"></div>
<div class="section">
    <h5>2014</h5>
    <div class="row">
<p> Simon S. Woo and Jelena Mirkovic, "Optimal application allocation on multiple public clouds", Elsevier Computer Networks, February 2014. (<b><font color='purple'>SCIE Q1 IF=2.52</font></b>) (pdf) </p>

<p> Simon S. Woo, Jelena Mikovic, Ron Artstein, and Elsi Kaiser, "Life-Experice Passwords", Who are you?! Adventures in Authentication: ACM SOUPS-WAY Workshop, 2014, Menlo Park, CA (pdf) </p>

<p> Simon S. Woo, and B. Kim, "3D Object CAPTCHA", Information Sciences Institute Graduate Student Symposium (ISI-GSS), Nov, 2014 (Best Student Paper) </p>

<p> Simon S. Woo*, B. Kim, W. Jun, and J. Kim, "3DOC: 3D Object CAPTCHA", 23rd International World Wide Web (WWW) Conference, 2014 (Poster) </p>

<p> Simon S. Woo, Jelena Mirkovic, and Elsi Kaiser, "Life Experience-Passwords", Network and Distributed System Security (NDSS) Symposium, Feb, 2014 (Poster) </p>
    </div>
</div>
<div class="divider"></div>
<div class="section">
    <h5>2011</h5>
    <div class="row">
<p> Simon S. Woo*, "Analysis of Proximity-1 Space Link Interleaved Time Synchronization Protocol", IEEE Globecom 2011, Houston, TX (Acceptance rate: 36%) (pdf) </p>
    </div>
</div>

<div class="divider"></div>
<div class="section">
    <h5>2010</h5>
    <div class="row">
<p> E. Jennings, J. Segui, and Simon S. Woo*, "MACHETE: A Protocol Evaluation Tool for Space- Based Networking Architecture and Simulation", AIAA SpaceOps 2010, Huntsville, AL (pdf) </p>

<p> Simon S. Woo, David Mills, and J. Gao, "Space Time Distribution and Synchronization Protocol Development for Mars Proximity Link", AIAA SpaceOps 2010 (Invited for Book Chapter) (pdf) </p>
    </div>
</div>

<div class="divider"></div>
<div class="section">
    <h5>2009</h5>
    <div class="row">
<p> E. Jennings, R. Borgen, C. Chevalier, E. Wesley, Sam Nguyen, John Segui, Tudor Stoenescu, Shin-Ywan Wang, and Simon S. Woo, "Space Communications and Navigation (SCaN) Network Simulation Tool Development and Its Use Cases", AIAA, Modeling and Simulation Technologies (AIAA MST) Conference, 2009 (pdf) </p>

<p> Simon S. Woo* and Tudor Stoenescu, "Efficient File Sharing by multicast - P2P protocol using network coding and rank based peer selection",IEEE 69th Vehicular Technology Conference (IEEE VTC) 2009-Spring, Barcelona, Spain, April, 2009 (pdf) </p>
    </div>
</div>

<div class="divider"></div>
<div class="section">
    <h5>2008</h5>
    <div class="row">
<p> Esther H. Jennings, Sam P. Nguyen, Shin-Ywan Wang, and Simon S. Woo*, "Interfacing Space Communications and Navigation Network Simulation with Distributed System Integration Laboratories (DSIL)", AIAA SpaceOps 2008 (pdf) </p>

<p> Simon S. Woo* and Mike Cheng, "Prioritized LT codes", IEEE Annual Conference on Information Sciences and Systems (CISS), Princeton, NJ, March 2008. (pdf) </p>
 
<p> Simon S. Woo, Esther Jennings, and Loren Clare, "A Simulation Tool for ASCTA Microsensor Network Architecture", IEEE Aerospace Conference, Big Sky, MT, March, 2008 (pdf) </p>
    </div>
</div>
<div class="divider"></div>
<div class="section">
    <h5>2007</h5>
    <div class="row">
Mike Cheng, Simon S. Woo, Kar-Ming Cheung, Sam Dolinar, and Jon Hamkins, "Improved In Situ Communications Using Network Coding", Research and Technology Development Poster session, (R&TD), Pasadena, Nov, 2007 </p>
    </div>
</div>
<div class="divider"></div>
<div class="section">
    <h5>2006</h5>
    <div class="row">
<p> Simon S. Woo and Jay Gao, "CFDP Performance Over Weather-Dependent Ka-Band Channel", AIAA SpaceOps 2006, Rome, Italy (pdf) </p>
    </div>
</div> -->
