---
layout: page
permalink: /mirae_facctrec/
---


<h2 class="page-title"> Discussion about Attacks and Defenses  for Fair and Robust Recommendation System Design</h2>
<p align=center><b><em>Mirae Kim and Simon Woo</em></b></p><br>
<p align=center><b><a href="https://drive.google.com/file/d/1GCFC0AcXI38fX7tec-s0U1AYIG-A8yOL/view?usp=sharing">Paper</a></b></p><br>
<h6><b>Abstract</b></h6>
  <p>Information has exploded on the Internet and mobile with the advent of the big data era. In particular, recommendation systems are widely used to help consumers who struggle to select the best products among such a large amount of information. However, recommendation systems are vulnerable to malicious user biases, such as fake reviews to promote or demote specific products and attacks that steal personal information. Such biases and attacks compromise the fairness of the recommendation model and infringe the privacy of users and systems by distorting data. Recently, deep-learning collaborative filtering recommendation systems have shown to be more vulnerable to this bias. In this position paper, we examine the effects of bias that cause various ethical and social issues and discuss the need for designing a robust recommendation system for fairness and stability.</p>
<br>
<table>
  <tr>
    <td width="63%" valign=top>
      <p align=center><img border=0 width=540 height=240 src="/Publications/facctrec_mirae22.png"></p>
    </td>
  </tr>
</table>
